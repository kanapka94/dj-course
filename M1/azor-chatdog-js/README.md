# Azor the ChatDog ğŸ•

Interactive terminal-based chat application with multi-LLM support. TypeScript port of the Python version.

## Features

- **Multi-session Support:** Create, load, and switch between multiple chat sessions
- **Persistent History:** All conversations saved to disk automatically
- **Token Management:** Real-time token counting and context awareness
- **Dual LLM Backend:** Support for both Google Gemini and local LLaMA models
- **Advanced CLI:** Interactive command-line interface with Tab autocompletion
- **Smart Autocompletion:** Context-aware command and subcommand completion
- **Session Export:** Export conversations to PDF (coming soon)
- **Audit Trail:** Write-Ahead Log for transaction history

## Installation

```bash
# Install dependencies
npm install

# Build the project
npm run build
```

## Configuration

Create a `.env` file in the root directory:

```bash
# Copy the example
cp .env.example .env

# Edit with your settings
```

### Gemini Configuration

```bash
ENGINE=GEMINI
GEMINI_API_KEY=your_api_key_here
MODEL_NAME=gemini-2.5-flash
```

Get your API key from [Google AI Studio](https://aistudio.google.com/apikey)

### LLaMA Configuration

```bash
ENGINE=LLAMA_CPP
MODEL_NAME=llama-3.1-8b-instruct
LLAMA_MODEL_PATH=/path/to/model.gguf
LLAMA_GPU_LAYERS=1
LLAMA_CONTEXT_SIZE=2048
```

## Usage

### Run in Development Mode

```bash
npm run dev
```

### Run Built Version

```bash
npm run build
npm start
```

### Run with Specific Session

```bash
npm start -- --session-id=<SESSION_ID>
```

### Using Autocompletion

The CLI supports **Tab autocompletion** for commands and subcommands:

**Main Commands:**
- Type `/` and press `Tab` to see all available commands
- Type `/ses` and press `Tab` to autocomplete to `/session`

**Subcommands:**
- Type `/session ` (with space) and press `Tab` to see all subcommands
- Type `/session l` and press `Tab` to autocomplete to `/session list`

**Example Flow:**
1. Type `/se` + `Tab` â†’ auto-completes to `/session`
2. Add space and `Tab` â†’ shows: `list`, `display`, `new`, `clear`, `pop`, `remove`
3. Type `l` + `Tab` â†’ auto-completes to `/session list`

## Available Commands

### Session Management

- `/session list` - List all saved sessions
- `/session display` - Display current session history
- `/session new` - Create a new session
- `/session clear` - Clear current session history
- `/session pop` - Remove last message exchange
- `/session remove` - Remove current session and start new
- `/switch <SESSION_ID>` - Switch to a different session

### Export

- `/pdf` - Export session to PDF (coming soon)

### General

- `/help` - Show help message
- `/exit` or `/quit` - Exit the application

## Project Structure

```
azor_js/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ assistant/          # Assistant configuration
â”‚   â”‚   â”œâ”€â”€ assistant.ts
â”‚   â”‚   â””â”€â”€ azor.ts
â”‚   â”œâ”€â”€ cli/                # Command-line interface
â”‚   â”‚   â”œâ”€â”€ args.ts
â”‚   â”‚   â”œâ”€â”€ console.ts
â”‚   â”‚   â””â”€â”€ prompt.ts
â”‚   â”œâ”€â”€ commands/           # Slash commands
â”‚   â”‚   â”œâ”€â”€ sessionList.ts
â”‚   â”‚   â”œâ”€â”€ sessionDisplay.ts
â”‚   â”‚   â”œâ”€â”€ sessionRemove.ts
â”‚   â”‚   â””â”€â”€ welcome.ts
â”‚   â”œâ”€â”€ files/              # File persistence
â”‚   â”‚   â”œâ”€â”€ config.ts
â”‚   â”‚   â”œâ”€â”€ sessionFiles.ts
â”‚   â”‚   â””â”€â”€ wal.ts
â”‚   â”œâ”€â”€ llm/                # LLM clients
â”‚   â”‚   â”œâ”€â”€ geminiClient.ts
â”‚   â”‚   â”œâ”€â”€ geminiValidation.ts
â”‚   â”‚   â”œâ”€â”€ llamaClient.ts
â”‚   â”‚   â””â”€â”€ llamaValidation.ts
â”‚   â”œâ”€â”€ session/            # Session management
â”‚   â”‚   â”œâ”€â”€ chatSession.ts
â”‚   â”‚   â””â”€â”€ sessionManager.ts
â”‚   â”œâ”€â”€ types/              # TypeScript types
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”œâ”€â”€ chat.ts             # Main chat loop
â”‚   â”œâ”€â”€ commandHandler.ts   # Command routing
â”‚   â””â”€â”€ run.ts              # Entry point
â”œâ”€â”€ .env                    # Environment variables
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â””â”€â”€ README.md
```

## Architecture

The application follows a clean layered architecture:

1. **CLI Layer:** User interface and input handling
2. **Command Layer:** Slash command processing
3. **Session Layer:** Session lifecycle management
4. **LLM Layer:** Abstract LLM client interface with Gemini and LLaMA implementations
5. **Storage Layer:** File persistence and Write-Ahead Log

### Key Components

- **ChatSession:** Manages a single chat session with history and LLM interaction
- **SessionManager:** Orchestrates session lifecycle (create, switch, save)
- **GeminiLLMClient:** Google Gemini API integration
- **LlamaClient:** Local LLaMA model integration
- **Assistant:** AI assistant configuration and personality

## Data Storage

All data is stored in `~/.azor/`:

- `<session-id>-log.json` - Session history files
- `azor-wal.json` - Write-Ahead Log for audit trail

## Development

### Watch Mode

```bash
npm run watch
```

### Clean Build

```bash
npm run clean
npm run build
```

## Dependencies

### Core

- `@google/generative-ai` - Google Gemini API client
- `node-llama-cpp` - Local LLaMA model support
- `dotenv` - Environment variable management
- `zod` - Runtime type validation
- `uuid` - UUID generation

### CLI

- `chalk` - Terminal colors
- `inquirer` - Interactive prompts

### Utilities

- `markdown-it` - Markdown parsing
- `pdf-lib` - PDF generation

## License

MIT

## Credits

TypeScript port of the original Python implementation. Maintains 1:1 feature parity with the Python version.
