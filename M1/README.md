# M1: LLMy i Agenty: Architektura i Działanie

## for windows users

Podobno instalowanie llama.cpp na Windowsie jest bardzo wygodne przy użyciu: `winget install llama.cpp`

## część pierwsza

- `embedding` - trenujemy model embeddingowy (czyli model kojarzący najbliższe słowa lub najbliższe zdania)
- **bazowy kod klientów** zewn. LLM (wymaga pdania klucza):
  - `external-model-anthropic-node`, `external-model-anthropic-py` - kod anthropickowy
  - `external-model-google-genai-node`, `external-model-google-genai-py` - kod google'owski
  - `external-model-openai-node`, `external-model-openai-py` - kod openAI'owy
- `jupyter` - lokalny setup pod jupyter notebook
  - sample google colab: https://colab.research.google.com/drive/1iOVHEodRAJiOUAaczd-71W7dbWTziHI3
- **korpusy** do wykorzystania w tokenizacji i trenowaniu modeli
  - `korpus-wolnelektury` - statyczne pliki `.txt` z literaturą piękną z serwisu WolneLektury.pl
  - `korpus-nkjp` - kod do (prze)tworzenia podkorpusu milionowego NKJP, 
- **local models**:
  - `local-ollama` - pliki `Modelfile`, służące w `ollama` do stworzenia nowej wersji/nakładki dla modelu LLM
  - `local-llama.cpp` - llama.cpp
- `mlflow` - nasłuchiwanie interackji agent-model przy użyciu mlflow, claude/llama
  - lokalny serwer `llama-cpp-python`
- `szczypta machine-learning` - ilustracja w formie kodu najważniejszych operacji tensorowych w ML (te same rzeczy robi pytorch/tensorflow, ale tu jest to pokazane "od zera")
- `tokenizer` - tworzymy własny BPE (byte-pair encoding), czyli słownik dla modelu językowego, a także uruchamiamy analitykę

## część druga

- `agents` - przykładowe mikro-implementacje agentowe
- `azor-the-chatdog` - czatowa aplikacja agentowa która posłuży nam jako baza do licznych ćwiczeń
- `claude` - przykładowe definicje claude (subagents, commands, skills), patrz w folder `.claude` (z kropką!)
- `sequence-diagrams` - diagramy sekwencji mermaid ilustrujące waorce aplikacji agentowych
